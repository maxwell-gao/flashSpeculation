\textbf{Impact Statement.}
This paper studies generative models of activations.
We find that the approach is useful for traditional interpretability tasks like steering and probing, especially when trained with increasing amounts of compute.
We caution future researchers to remain cognizant of the environmental impact associated with large-scale training.
Overall, we believe that our method poses minimal safety risks, as it can only directly generate activations, unlike generative models of images or text which can be misused for harmful content generation.